"""Enhanced message console with resume viewing, scoring, and AI drafting."""
from __future__ import annotations

from pathlib import Path
from typing import Any, Dict, List, Optional

import streamlit as st

from streamlit_shared import call_api, ensure_state, sidebar_controls, SessionKeys, get_selected_job

COMPANY_MD_PATH = Path("config/company.md")
DEFAULT_HISTORY_LIMIT = 10

# ---------------------------------------------------------------------------
# Data loaders and helpers
# ---------------------------------------------------------------------------



@st.cache_data(ttl=600, show_spinner="è·å–æ¶ˆæ¯åˆ—è¡¨ä¸­...")
def _get_dialogs(limit: int, tab: str = 'æ–°æ‹›å‘¼', status: str = 'æœªè¯»', job_title: str = 'å…¨éƒ¨') -> List[Dict[str, Any]]:
    """Cached message fetching - depends only on inputs, not session state."""
    params = {
        "limit": limit,
        "tab": tab,
        "status": status,
        "job_title": job_title
    }
    ok, payload = call_api("GET", "/chat/dialogs", params=params)
    if not ok:
        raise ValueError(f"è·å–æ¶ˆæ¯åˆ—è¡¨å¤±è´¥: {payload}")
    if not isinstance(payload, list):
        raise ValueError("API è¿”å›çš„æ¶ˆæ¯æ ¼å¼ä¸ç¬¦åˆé¢„æœŸ") 
    return payload

@st.cache_data(ttl=300, show_spinner="è·å–ç®€å†ä¸­...")
def _fetch_resume(chat_id: str, endpoint: str) -> Optional[Dict[str, Any]]:
    """Fetch resume data with Streamlit caching."""
    ok, payload = call_api("POST", endpoint, json={"chat_id": chat_id})
    if not ok or not isinstance(payload, dict):
        # Don't cache errors - raise exception to skip caching
        raise ValueError(f"è·å–ç®€å†å¤±è´¥: {payload}")
    return payload


@st.cache_data(ttl=300, show_spinner="è·å–èŠå¤©è®°å½•ä¸­...")
def _fetch_history(chat_id: str) -> List[str]:
    """Fetch chat history with Streamlit caching."""
    ok, payload = call_api("GET", f"/chat/{chat_id}/messages")
    if not ok or not isinstance(payload, list):
        raise ValueError(f"è·å–èŠå¤©è®°å½•å¤±è´¥: {payload}")
    return payload


def pass_and_next(dialogs: List[Dict[str, Any]], current_chat_id: str) -> None:
    """Move to the next candidate in the dialog list."""
    if not dialogs:
        st.warning("æ²¡æœ‰æ›´å¤šå€™é€‰äººäº†")
        return
    
    # Find current index
    current_index = None
    for i, dialog in enumerate(dialogs):
        if dialog.get("id") == current_chat_id:
            current_index = i
            break
    
    if current_index is None:
        st.warning("æœªæ‰¾åˆ°å½“å‰å€™é€‰äºº")
        return
    
    # Move to next candidate
    next_index = current_index + 1
    if next_index >= len(dialogs):
        st.info("å·²ç»æ˜¯æœ€åä¸€ä¸ªå€™é€‰äººäº†")
        return
    
    # Update session state to select next candidate
    next_chat_id = dialogs[next_index]["id"]
    st.session_state[SessionKeys.SELECTED_CHAT_ID] = next_chat_id
    
    # Clear cached data for the new candidate
    _fetch_resume.clear()
    _fetch_history.clear()
    
    st.success(f"å·²åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªå€™é€‰äºº: {dialogs[next_index].get('name', 'Unknown')}")
    st.rerun()


def _fetch_best_resume(chat_id: str) -> tuple[str, str]:
    """
    Fetch best available resume (full resume preferred, online as fallback).
    
    Cached for 10 minutes to improve performance.
    
    Returns:
        tuple[str, str]: (resume_text, source) where source is "é™„ä»¶ç®€å†" or "åœ¨çº¿ç®€å†"
    """
    # Step 1: Check if full resume is available
    full_resume_available = check_full_resume(chat_id)
    
    # Step 2: Get full resume if available
    if full_resume_available:
        full_payload = _fetch_full_resume(chat_id)
        if full_payload.get("success"):
            resume_text = full_payload.get("text", "")
            if resume_text:
                return resume_text, "é™„ä»¶ç®€å†"
            else:
                st.error(f"è·å–é™„ä»¶ç®€å†å¤±è´¥: {full_payload}")
    
    # Step 3: Fallback to online resume
    online_payload = _fetch_online_resume(chat_id)
    if online_payload.get("success"):
        resume_text = online_payload.get("text", "")
        if resume_text:
            return resume_text, "åœ¨çº¿ç®€å†"
        else:
            st.error(f"è·å–åœ¨çº¿ç®€å†å¤±è´¥: {online_payload}")
    
    return None, "æ— "

@st.cache_data(ttl=300, show_spinner="æ£€æŸ¥ç®€å†ä¸­...")
def check_full_resume(chat_id: str) -> bool:
    """Check if full resume is available."""
    ok, available = call_api("POST", "/resume/check_full_resume_available", json={"chat_id": chat_id})
    return ok and available

@st.cache_data(show_spinner="è·å–ç®€å†ä¸­...")
def _fetch_full_resume(chat_id: str) -> Dict[str, Any]:
    """Fetch full resume with Streamlit caching."""
    ok, payload = call_api("POST", "/resume/view_full", json={"chat_id": chat_id})
    if not ok or not payload.get('success'): 
        raise ValueError(f"è·å–ç®€å†å¤±è´¥: {payload}")
    return payload


@st.cache_data(show_spinner="è·å–åœ¨çº¿ç®€å†ä¸­...")
def _fetch_online_resume(chat_id: str) -> Dict[str, Any]:
    """Fetch online resume with Streamlit caching."""
    ok, payload = call_api("POST", "/resume/online", json={"chat_id": chat_id})
    if not ok or not isinstance(payload, dict):
        raise ValueError(f"è·å–ç®€å†å¤±è´¥: {payload}")
    return payload



# ---------------------------------------------------------------------------
# UI components
# ---------------------------------------------------------------------------

def render_resume_section(
    title: str,
    chat_id: str,
    endpoint: str,
    cache_key: str,
    request_when_missing: bool = False,
    check_endpoint: Optional[str] = None,
) -> str:
    """
    æ¸²æŸ“ç®€å†å±•ç¤ºåŒºå—ï¼Œæ”¯æŒåŠ è½½ã€åˆ·æ–°ã€å¯é€‰çš„å¯ç”¨æ€§æ£€æŸ¥å’Œç®€å†è¯·æ±‚ã€‚

    å‚æ•°:
        title (str): å±•å¼€åŒºå—æ ‡é¢˜ã€‚
        chat_id (str): èŠå¤©ä¼šè¯IDã€‚
        endpoint (str): è·å–ç®€å†çš„APIç«¯ç‚¹ã€‚
        cache_key (str): ç”¨äºç¼“å­˜çš„å”¯ä¸€é”®ã€‚
        request_when_missing (bool): è‹¥ç®€å†ä¸å¯ç”¨æ—¶æ˜¯å¦å…è®¸è¯·æ±‚ç®€å†ã€‚
        check_endpoint (Optional[str]): æ£€æŸ¥ç®€å†å¯ç”¨æ€§çš„APIç«¯ç‚¹ï¼ˆå¯é€‰ï¼‰ã€‚

    è¿”å›:
        str: ç®€å†æ–‡æœ¬å†…å®¹ï¼ˆå¦‚æœ‰ï¼‰ï¼Œå¦åˆ™ä¸ºç©ºå­—ç¬¦ä¸²ã€‚
    """
    text = ""
    load_state_key = f"loaded_{cache_key}_{chat_id}"
    with st.expander(title, expanded=False):
        cols = st.columns([1, 1, 3])
        if cols[0].button("åŠ è½½", key=f"load_{cache_key}_{chat_id}"):
            st.session_state[load_state_key] = True

        load_state = st.session_state.get(load_state_key, False)
        if not load_state:
            st.caption("ç‚¹å‡»â€œåŠ è½½â€ä»¥è·å–å†…å®¹ã€‚")
            return text

        if st.session_state[load_state_key]:
            data = _fetch_resume(chat_id, endpoint)
            success = bool(data and data.get("success", True))
        if not success:
            details = data.get("details") if data else None
            st.warning(details or "æ— æ³•è·å–ç®€å†ã€‚")
            return text

        text = data.get("text") or data.get("content") or ""
        if text:
            st.text_area("å†…å®¹", value=text, height=300)
        else:
            st.info("æš‚æ— å¯æ˜¾ç¤ºçš„ç®€å†æ–‡æœ¬ã€‚")
        return text


def render_history_section(history: List[Dict[str, Any]]) -> None:
    """Render history section UI (separated from data fetching)"""
    with st.expander("å¯¹è¯è®°å½•", expanded=True):
        # Format history data for better table display
        formatted_history = []
        for item in history:
            type_emoji = "ğŸ‘¤" if item.get('type') == 'candidate' else "ğŸ¢"
            status_emoji = "âœ…" if item.get('status') == 'processed' else "â³" if item.get('status') else "â“"
            formatted_item = {
                'ç±»å‹': f"{type_emoji} {'å€™é€‰äºº' if item.get('type') == 'candidate' else 'HR'}",
                'æ—¶é—´': item.get('timestamp', ''),
                'æ¶ˆæ¯å†…å®¹': item.get('message', ''),
                'çŠ¶æ€': f"{status_emoji} {item.get('status') if item.get('status') else 'æœªå¤„ç†'}"
            }
            formatted_history.append(formatted_item)
        import pandas as pd
        df = pd.DataFrame(history)
        st.dataframe(
            df, 
            width="stretch", 
            hide_index=True,
            column_config={
                "ç±»å‹": st.column_config.TextColumn("ç±»å‹", width="small"),
                "æ—¶é—´": st.column_config.TextColumn("æ—¶é—´", width="medium"),
                "æ¶ˆæ¯å†…å®¹": st.column_config.TextColumn("æ¶ˆæ¯å†…å®¹", width="large"),
                "çŠ¶æ€": st.column_config.TextColumn("çŠ¶æ€", width="small")
            }
        )


@st.cache_data(show_spinner="åˆ†æä¸­...")
def _analyze_candidate(chat_id: str, assistant_id: str, history: list[dict]) -> Dict[str, Any]:
    context = {
        "chat_id": chat_id,
        "assistant_id": assistant_id,
        "chat_history": history,
        "purpose": "analyze",
        # "instruction": "è¯·æ ¹æ®å²—ä½æè¿°ï¼Œå¯¹å€™é€‰äººçš„ç®€å†è¿›è¡Œæ‰“åˆ†ï¼Œç”¨äºå†³å®šæ˜¯å¦ç»§ç»­æ¨è¿›ã€‚",
    }
    ok, generated_message = call_api(
        "POST", "/assistant/generate-message",
        json=context
        )
    if ok:
        get_thread_messages.clear()
        st.session_state.setdefault(SessionKeys.ANALYSIS_RESULTS, {})[chat_id] = generated_message
        return generated_message
    else:
        raise ValueError(f"æ— æ³•è§£æè¯„åˆ†ç»“æœ: {generated_message}")

@st.cache_data(show_spinner="è·å–å€™é€‰äººä¸­...")
def get_candidate_by_id(chat_id: str) -> Dict[str, Any]:
    """Get candidate by ID."""
    ok, payload = call_api("GET", f"/candidate/{chat_id}")
    if not ok or not isinstance(payload, dict):
        raise ValueError(f"è·å–å€™é€‰äººå¤±è´¥: {payload}")
    assert payload.get('resume_text'), "è·å–å€™é€‰äººå¤±è´¥: æ²¡æœ‰ç®€å†æ•°æ®"
    return payload


def init_chat(chat_id: str, name: str, job_info: dict, resume_text: str, chat_history: list[dict]) -> bool:
    """Init chat."""
    ok, payload = call_api("POST", "/thread/init-chat", json={
        "name": name,
        "chat_id": chat_id,
        "job_info": job_info,
        "resume_text": resume_text,
        "chat_history": chat_history
    })
    get_candidate_by_id.clear()
    return ok


@st.cache_data(show_spinner="è·å–threadèŠå¤©è®°å½•ä¸­...")
def get_thread_messages(thread_id: str) -> list[dict]:
    """Get thread messages."""
    ok, payload = call_api("GET", f"/thread/{thread_id}/messages")
    if not ok or not isinstance(payload, list):
        raise ValueError(f"è·å–èŠå¤©è®°å½•å¤±è´¥: {payload}")
    return payload


def generate_message(chat_id: str, assistant_id: str, history: list[dict]) -> Dict[str, Any]:
    """Generate message."""
    ok, generated_message = call_api("POST", "/assistant/generate-message", json={
        "chat_id": chat_id,
        "assistant_id": assistant_id,
        "chat_history": history,
        "purpose": "chat"
    })
    return generated_message


# ---------------------------------------------------------------------------
# Main entrypoint
# ---------------------------------------------------------------------------

def main() -> None:
    st.title("æ¶ˆæ¯åˆ—è¡¨")
    ensure_state()
    sidebar_controls(include_config_path=False, include_job_selector=True)
    limit = st.sidebar.slider("æ¯æ¬¡è·å–å¯¹è¯æ•°é‡", min_value=5, max_value=100, value=30, step=5)
    assistant_id = st.session_state.get(SessionKeys.SELECTED_ASSISTANT_ID)
    # Sync job selection
    selected_job_idx = st.session_state.get(SessionKeys.SELECTED_JOB_INDEX, 0)
    job_info = get_selected_job(selected_job_idx)
    job_title = job_info.get("position")
    # === Filter Controls ===
    col1, col2 = st.columns(2)
    
    with col1:
        tab_filter = st.radio(
            "èŠå¤©æ ‡ç­¾",
            options=['å…¨éƒ¨', 'æ–°æ‹›å‘¼', 'æ²Ÿé€šä¸­'],
            index=0,
            help="é€‰æ‹©è¦æŸ¥çœ‹çš„èŠå¤©æ ‡ç­¾",
            horizontal=True
        )
    
    with col2:
        status_filter = st.radio(
            "æ¶ˆæ¯çŠ¶æ€",
            options=['å…¨éƒ¨', 'æœªè¯»', 'ç‰›äººå·²è¯»æœªå›'],
            index=0,
            help="é€‰æ‹©è¦æŸ¥çœ‹çš„æ¶ˆæ¯çŠ¶æ€",
            horizontal=True
        )
    
    
    # === Data Loading Phase (cached, fast) ===
    dialogs = _get_dialogs(limit, tab_filter, status_filter, job_title)

    if not dialogs:
        st.info("æš‚æ— èŠå¤©å¯¹è¯æ•°æ®ã€‚ã€‚ã€‚")
        return
    # å¯¹è¯ä¸‹æ‹‰æ¡†
    col_select, col_refresh = st.columns([9, 1])
    
    # Get current selection from session state or default to first dialog
    current_selection = st.session_state.get(SessionKeys.SELECTED_CHAT_ID)
    default_index = 0
    if current_selection:
        try:
            default_index = next(i for i, row in enumerate(dialogs) if row['id'] == current_selection)
        except StopIteration:
            default_index = 0
    
    chat_id = col_select.selectbox(
        'None',
        options=[row["id"] for row in dialogs],
        format_func=lambda cid: next(
            (f"{row['name']}({row['job_title']}):{row['text']}" for row in dialogs if row['id'] == cid),
            cid,
        ),
        key="chat_selector",
        index=default_index,
        label_visibility="collapsed",
    )
    
    # Update session state when selection changes
    if chat_id != current_selection:
        st.session_state[SessionKeys.SELECTED_CHAT_ID] = chat_id
    # é€‰ä¸­å¯¹è¯
    selected_dialog = next((row for row in dialogs if row['id'] == chat_id), None)
    if col_refresh.button("ğŸ”„", key="refresh_messages_main"):
        _get_dialogs.clear()
        st.rerun()

    # Null safety check
    if not selected_dialog:
        st.warning("æœªèƒ½æ‰¾åˆ°é€‰ä¸­çš„å€™é€‰äººï¼Œè¯·åˆ·æ–°åˆ—è¡¨é‡è¯•")
        return

    # === Data Fetching Phase (upfront, cached by Streamlit) ===
    try:
        record_exists =False
        candidate_object = get_candidate_by_id(chat_id)
        record_exists = True
    except Exception as e:
        # cannot create a new candidate without resume_text
        candidate_object = {
            "name": selected_dialog.get("name"), 
            "job_applied": job_title}

    resume_text = candidate_object.get("resume_text")
    full_resume = candidate_object.get("full_resume")
    if not resume_text:
        # Fetch resume data (cached by @st.cache_data for 10 minutes)
        resume_text, resume_source = _fetch_best_resume(chat_id)
        # append_resume_to_thread_and_store(chat_id, resume_text, resume_source)
    else:
        if full_resume:
            resume_source = "é™„ä»¶ç®€å†"
        else:
            resume_source = "åœ¨çº¿ç®€å†"
    assert resume_text, "æ— æ³•è·å–ç®€å†æ•°æ®"
    
    # Fetch history data (cached by @st.cache_data for 5 minutes)
    chat_messages = _fetch_history(chat_id)

    if not record_exists:
        # init chat
        suceess = init_chat(chat_id, selected_dialog.get("name"), job_info, resume_text, chat_messages)
        if not suceess:
            st.error("åˆå§‹åŒ–èŠå¤©å¤±è´¥")
            return

    # === UI Rendering Phase (display data in expanders) ===
    # Resume expanders - now filled with cached data
    with st.expander("ç®€å†ä¿¡æ¯", expanded=bool(resume_text)):
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ç®€å†æ¥æº", resume_source)
        with col2:
            if st.button("ğŸ”„ åˆ·æ–°ç®€å†", key=f"refresh_resume_{chat_id}"):
                # Clear Streamlit cache and reload
                _fetch_online_resume.clear()
                _fetch_full_resume.clear()
                st.rerun()
        
        if resume_text:
            st.text_area("ç®€å†å†…å®¹", value=resume_text, height=300, key=f"resume_display_{chat_id}")
        else:
            st.warning("æš‚æ— ç®€å†æ•°æ®")
    
    # History expander - now filled with fetched data
    render_history_section(chat_messages)

    # === Scoring Section (user-triggered) ===
    st.subheader("è‡ªåŠ¨è¯„åˆ†")

    # Display analysis results
    # analysis_result = st.session_state.get(SessionKeys.ANALYSIS_RESULTS, {}).get(chat_id)
    analysis_result = candidate_object.get("analysis")
    if not analysis_result:
        analysis_result = st.session_state.get(SessionKeys.ANALYSIS_RESULTS, {}).get(chat_id)
    if analysis_result:
        cols = st.columns(4)
        cols[0].metric("æŠ€èƒ½åŒ¹é…", analysis_result.get("skill"))
        cols[1].metric("åˆ›ä¸šå¥‘åˆ", analysis_result.get("startup_fit"))
        cols[2].metric("åŠ å…¥æ„æ„¿", analysis_result.get("willingness"))
        cols[3].metric("ç»¼åˆè¯„åˆ†", analysis_result.get("overall"), help='1-10åˆ†, å¦‚æœéœ€è¦è°ƒæ•´è¯„åˆ†ï¼Œè¯·ä¿®æ”¹åŠ©æ‰‹é…ç½®')
        st.markdown(f"**åˆ†ææ€»ç»“ï¼š** {analysis_result.get('summary', 'â€”')}")

    else:
        analysis_result = _analyze_candidate(chat_id, assistant_id, chat_messages)
        st.session_state.setdefault(SessionKeys.ANALYSIS_RESULTS, {})[chat_id] = analysis_result
        st.rerun()

    # === Message Section (user-triggered) ===
    st.subheader("ç”Ÿæˆæ¶ˆæ¯")
    last_message = st.session_state.setdefault(SessionKeys.GENERATED_MESSAGES, {}).get(chat_id)
    draft_message = st.empty()
    draft = draft_message.text_area("æ¶ˆæ¯å†…å®¹", value=last_message, height=180, key=f"message_draft_{chat_id}")
    col_generate, col_send = st.columns(2)
    # Generate button
    if col_generate.button("ç”Ÿæˆå»ºè®®", key=f"generate_msg_{chat_id}", disabled=bool(draft)):
        followup_message = generate_message(chat_id, assistant_id, chat_messages)
        draft_message.text_area("æ¶ˆæ¯å†…å®¹", value=followup_message, height=180)
        st.session_state.setdefault(SessionKeys.GENERATED_MESSAGES, {})[chat_id] = followup_message
        st.rerun()

    # Send button
    if col_send.button("å‘é€æ¶ˆæ¯", key=f"send_msg_{chat_id}", disabled=not bool(draft)):
        content = draft.strip()
        if not content:
            st.warning("æ¶ˆæ¯å†…å®¹ä¸èƒ½ä¸ºç©º")
        else:
            with st.spinner("å‘é€ä¸­..."):
                ok, payload = call_api(
                    "POST",
                    f"/chat/{chat_id}/send",
                    json={"message": content},
                )
                success = ok
            if success:
                st.success("æ¶ˆæ¯å·²å‘é€")
            else:
                st.error("å‘é€å¤±è´¥")

    # pass and next button
    if st.button("PASSï¼ŒæŸ¥çœ‹ä¸‹ä¸€ä¸ªå€™é€‰äºº", key=f"pass_and_next_{chat_id}"):
        pass_and_next(dialogs, chat_id)
if __name__ == "__main__":
    main()
