"""Enhanced message console with resume viewing, scoring, and AI drafting."""
from __future__ import annotations

from pathlib import Path
from typing import Any, Dict, List, Optional

import streamlit as st

from streamlit_shared import call_api, ensure_state, sidebar_controls, SessionKeys, get_selected_job

COMPANY_MD_PATH = Path("config/company.md")
DEFAULT_HISTORY_LIMIT = 10

# ---------------------------------------------------------------------------
# Data loaders and helpers
# ---------------------------------------------------------------------------



@st.cache_data(ttl=600, show_spinner="è·å–æ¶ˆæ¯åˆ—è¡¨ä¸­...")
def _get_dialogs_cached(limit: int, tab: str = 'æ–°æ‹›å‘¼', status: str = 'æœªè¯»', job_title: str = 'å…¨éƒ¨') -> List[Dict[str, Any]]:
    """Cached message fetching - depends only on inputs, not session state."""
    params = {
        "limit": limit,
        "tab": tab,
        "status": status,
        "job_title": job_title
    }
    ok, payload = call_api("GET", "/chat/dialogs", params=params)
    if not ok:
        raise ValueError(f"è·å–æ¶ˆæ¯åˆ—è¡¨å¤±è´¥: {payload}")
    if not isinstance(payload, list):
        raise ValueError("API è¿”å›çš„æ¶ˆæ¯æ ¼å¼ä¸ç¬¦åˆé¢„æœŸ")
    return payload

@st.cache_data(ttl=300, show_spinner="è·å–ç®€å†ä¸­...")
def _fetch_resume(chat_id: str, endpoint: str) -> Optional[Dict[str, Any]]:
    """Fetch resume data with Streamlit caching."""
    ok, payload = call_api("POST", endpoint, json={"chat_id": chat_id})
    if not ok or not isinstance(payload, dict):
        # Don't cache errors - raise exception to skip caching
        raise ValueError(f"è·å–ç®€å†å¤±è´¥: {payload}")
    return payload


@st.cache_data(ttl=300, show_spinner="è·å–èŠå¤©è®°å½•ä¸­...")
def _fetch_history(chat_id: str) -> List[str]:
    """Fetch chat history with Streamlit caching."""
    ok, payload = call_api("GET", f"/chat/{chat_id}/messages")
    if not ok or not isinstance(payload, list):
        raise ValueError(f"è·å–èŠå¤©è®°å½•å¤±è´¥: {payload}")
    return payload


def _fetch_best_resume(chat_id: str) -> tuple[str, str]:
    """
    Fetch best available resume (full resume preferred, online as fallback).
    
    Cached for 10 minutes to improve performance.
    
    Returns:
        tuple[str, str]: (resume_text, source) where source is "é™„ä»¶ç®€å†" or "åœ¨çº¿ç®€å†"
    """
    # Step 1: Check if full resume is available
    full_resume_available = check_full_resume(chat_id)
    
    # Step 2: Get full resume if available
    if full_resume_available:
        full_payload = _fetch_full_resume(chat_id)
        if full_payload.get("success"):
            resume_text = full_payload.get("text", "")
            if resume_text:
                return resume_text, "é™„ä»¶ç®€å†"
            else:
                st.error(f"è·å–é™„ä»¶ç®€å†å¤±è´¥: {full_payload}")
    
    # Step 3: Fallback to online resume
    online_payload = _fetch_online_resume(chat_id)
    if online_payload.get("success"):
        resume_text = online_payload.get("text", "")
        if resume_text:
            return resume_text, "åœ¨çº¿ç®€å†"
        else:
            st.error(f"è·å–åœ¨çº¿ç®€å†å¤±è´¥: {online_payload}")
    
    return "æ— ç®€å†æ•°æ®", "æ— "

@st.cache_data(ttl=300, show_spinner="æ£€æŸ¥ç®€å†ä¸­...")
def check_full_resume(chat_id: str) -> bool:
    """Check if full resume is available."""
    ok, available = call_api("POST", "/resume/check_full_resume_available", json={"chat_id": chat_id})
    return ok and available

@st.cache_data(show_spinner="è·å–ç®€å†ä¸­...")
def _fetch_full_resume(chat_id: str) -> Dict[str, Any]:
    """Fetch full resume with Streamlit caching."""
    ok, payload = call_api("POST", "/resume/view_full", json={"chat_id": chat_id})
    if not ok or not payload.get('success'): 
        raise ValueError(f"è·å–ç®€å†å¤±è´¥: {payload}")
    return payload


@st.cache_data(show_spinner="è·å–åœ¨çº¿ç®€å†ä¸­...")
def _fetch_online_resume(chat_id: str) -> Dict[str, Any]:
    """Fetch online resume with Streamlit caching."""
    ok, payload = call_api("POST", "/resume/online", json={"chat_id": chat_id})
    if not ok or not isinstance(payload, dict):
        raise ValueError(f"è·å–ç®€å†å¤±è´¥: {payload}")
    return payload



# ---------------------------------------------------------------------------
# UI components
# ---------------------------------------------------------------------------

def render_resume_section(
    title: str,
    chat_id: str,
    endpoint: str,
    cache_key: str,
    request_when_missing: bool = False,
    check_endpoint: Optional[str] = None,
) -> str:
    """
    æ¸²æŸ“ç®€å†å±•ç¤ºåŒºå—ï¼Œæ”¯æŒåŠ è½½ã€åˆ·æ–°ã€å¯é€‰çš„å¯ç”¨æ€§æ£€æŸ¥å’Œç®€å†è¯·æ±‚ã€‚

    å‚æ•°:
        title (str): å±•å¼€åŒºå—æ ‡é¢˜ã€‚
        chat_id (str): èŠå¤©ä¼šè¯IDã€‚
        endpoint (str): è·å–ç®€å†çš„APIç«¯ç‚¹ã€‚
        cache_key (str): ç”¨äºç¼“å­˜çš„å”¯ä¸€é”®ã€‚
        request_when_missing (bool): è‹¥ç®€å†ä¸å¯ç”¨æ—¶æ˜¯å¦å…è®¸è¯·æ±‚ç®€å†ã€‚
        check_endpoint (Optional[str]): æ£€æŸ¥ç®€å†å¯ç”¨æ€§çš„APIç«¯ç‚¹ï¼ˆå¯é€‰ï¼‰ã€‚

    è¿”å›:
        str: ç®€å†æ–‡æœ¬å†…å®¹ï¼ˆå¦‚æœ‰ï¼‰ï¼Œå¦åˆ™ä¸ºç©ºå­—ç¬¦ä¸²ã€‚
    """
    text = ""
    load_state_key = f"loaded_{cache_key}_{chat_id}"
    with st.expander(title, expanded=False):
        cols = st.columns([1, 1, 3])
        if cols[0].button("åŠ è½½", key=f"load_{cache_key}_{chat_id}"):
            st.session_state[load_state_key] = True

        load_state = st.session_state.get(load_state_key, False)
        if not load_state:
            st.caption("ç‚¹å‡»â€œåŠ è½½â€ä»¥è·å–å†…å®¹ã€‚")
            return text

        if st.session_state[load_state_key]:
            data = _fetch_resume(chat_id, endpoint)
            success = bool(data and data.get("success", True))
        if not success:
            details = data.get("details") if data else None
            st.warning(details or "æ— æ³•è·å–ç®€å†ã€‚")
            return text

        text = data.get("text") or data.get("content") or ""
        if text:
            st.text_area("å†…å®¹", value=text, height=300)
        else:
            st.info("æš‚æ— å¯æ˜¾ç¤ºçš„ç®€å†æ–‡æœ¬ã€‚")
        return text


def render_history_section(history: List[Dict[str, Any]]) -> None:
    """Render history section UI (separated from data fetching)"""
    with st.expander("å¯¹è¯è®°å½•", expanded=True):
        # Format history data for better table display
        formatted_history = []
        for item in history:
            type_emoji = "ğŸ‘¤" if item.get('type') == 'candidate' else "ğŸ¢"
            status_emoji = "âœ…" if item.get('status') == 'processed' else "â³" if item.get('status') else "â“"
            formatted_item = {
                'ç±»å‹': f"{type_emoji} {'å€™é€‰äºº' if item.get('type') == 'candidate' else 'HR'}",
                'æ—¶é—´': item.get('timestamp', ''),
                'æ¶ˆæ¯å†…å®¹': item.get('message', ''),
                'çŠ¶æ€': f"{status_emoji} {item.get('status') if item.get('status') else 'æœªå¤„ç†'}"
            }
            formatted_history.append(formatted_item)
        import pandas as pd
        df = pd.DataFrame(history)
        st.dataframe(
            df, 
            width="stretch", 
            hide_index=True,
            column_config={
                "ç±»å‹": st.column_config.TextColumn("ç±»å‹", width="small"),
                "æ—¶é—´": st.column_config.TextColumn("æ—¶é—´", width="medium"),
                "æ¶ˆæ¯å†…å®¹": st.column_config.TextColumn("æ¶ˆæ¯å†…å®¹", width="large"),
                "çŠ¶æ€": st.column_config.TextColumn("çŠ¶æ€", width="small")
            }
        )


@st.cache_data(show_spinner="åˆ†æä¸­...")
def _analyze_candidate(chat_id: str, assistant_id: str, history: list[dict]) -> Dict[str, Any]:
    context = {
        "chat_id": chat_id,
        "assistant_id": assistant_id,
        "chat_history": history,
        "purpose": "analyze",
        # "instruction": "è¯·æ ¹æ®å²—ä½æè¿°ï¼Œå¯¹å€™é€‰äººçš„ç®€å†è¿›è¡Œæ‰“åˆ†ï¼Œç”¨äºå†³å®šæ˜¯å¦ç»§ç»­æ¨è¿›ã€‚",
    }
    ok, payload = call_api(
        "POST", "/assistant/generate-message",
        json=context
        )
    if ok:
        get_thread_messages.clear()
        generated_message, thread_id = payload
        st.session_state.setdefault(SessionKeys.ANALYSIS_RESULTS, {})[chat_id] = generated_message
        return generated_message
    else:
        st.error(f"æ— æ³•è§£æè¯„åˆ†ç»“æœ: {payload}")
        raise ValueError(f"æ— æ³•è§£æè¯„åˆ†ç»“æœ: {payload}")

@st.cache_data(show_spinner="è·å–å€™é€‰äººä¸­...")
def get_candidate_by_id(chat_id: str) -> Dict[str, Any]:
    """Get candidate by ID."""
    ok, payload = call_api("GET", f"/candidate/{chat_id}", params={"fields": None})
    if not ok or not isinstance(payload, dict):
        raise ValueError(f"è·å–å€™é€‰äººå¤±è´¥: {payload}")
    return payload


def init_chat(chat_id: str, job_info: dict, resume_text: str, chat_history: list[dict]) -> bool:
    """Init chat."""
    ok, payload = call_api("POST", "/thread/init-chat", json={
        "chat_id": chat_id,
        "job_info": job_info,
        "resume_text": resume_text,
        "chat_history": chat_history
    })
    get_candidate_by_id.clear()
    return ok

@st.cache_data(show_spinner="è·å–threadèŠå¤©è®°å½•ä¸­...")
def get_thread_messages(thread_id: str) -> list[dict]:
    """Get thread messages."""
    ok, payload = call_api("GET", f"/thread/{thread_id}/messages")
    if not ok or not isinstance(payload, list):
        raise ValueError(f"è·å–èŠå¤©è®°å½•å¤±è´¥: {payload}")
    return payload

# ---------------------------------------------------------------------------
# Main entrypoint
# ---------------------------------------------------------------------------

def main() -> None:
    st.title("æ¶ˆæ¯åˆ—è¡¨")
    ensure_state()
    sidebar_controls(include_config_path=False, include_job_selector=True)
    limit = st.sidebar.slider("æ¯æ¬¡è·å–å¯¹è¯æ•°é‡", min_value=5, max_value=100, value=30, step=5)
    
    # Sync job selection
    selected_job_idx = st.session_state.get(SessionKeys.SELECTED_JOB_INDEX, 0)
    selected_job = get_selected_job(selected_job_idx)
    # === Filter Controls ===
    col1, col2 = st.columns(2)
    
    with col1:
        tab_filter = st.radio(
            "èŠå¤©æ ‡ç­¾",
            options=['å…¨éƒ¨', 'æ–°æ‹›å‘¼', 'æ²Ÿé€šä¸­'],
            index=0,
            help="é€‰æ‹©è¦æŸ¥çœ‹çš„èŠå¤©æ ‡ç­¾",
            horizontal=True
        )
    
    with col2:
        status_filter = st.radio(
            "æ¶ˆæ¯çŠ¶æ€",
            options=['å…¨éƒ¨', 'æœªè¯»', 'ç‰›äººå·²è¯»æœªå›'],
            index=0,
            help="é€‰æ‹©è¦æŸ¥çœ‹çš„æ¶ˆæ¯çŠ¶æ€",
            horizontal=True
        )
    
    
    # === Data Loading Phase (cached, fast) ===
    with st.spinner("è·å–èŠå¤©å¯¹è¯æ•°æ®ä¸­..."):
        job_title = selected_job.get("position")
        dialogs = _get_dialogs_cached(limit, tab_filter, status_filter, job_title)

    if not dialogs:
        st.info("æš‚æ— èŠå¤©å¯¹è¯æ•°æ®ã€‚ã€‚ã€‚")
        return
    # å¯¹è¯ä¸‹æ‹‰æ¡†
    col_select, col_refresh = st.columns([9, 1])
    chat_id = col_select.selectbox(
        'None',
        options=[row["id"] for row in dialogs],
        format_func=lambda cid: next(
            (f"{row['name']}({row['job_title']}):{row['text']}" for row in dialogs if row['id'] == cid),
            cid,
        ),
        key="chat_selector",
        index=1,
        label_visibility="collapsed",
    )
    # é€‰ä¸­å¯¹è¯
    selected_dialog = next((row for row in dialogs if row['id'] == chat_id), None)
    if col_refresh.button("ğŸ”„", key="refresh_messages_main"):
        _get_dialogs_cached.clear()
        st.rerun()

    # Null safety check
    if not selected_dialog:
        st.warning("æœªèƒ½æ‰¾åˆ°é€‰ä¸­çš„å€™é€‰äººï¼Œè¯·åˆ·æ–°åˆ—è¡¨é‡è¯•")
        return


    # === Data Fetching Phase (upfront, cached by Streamlit) ===
    try:
        candidate_object = get_candidate_by_id(chat_id)
        record_exists = True
    except Exception as e:
        # cannot create a new candidate without resume_text
        candidate_object = {
            "name": selected_dialog.get("name"), 
            "job_applied": job_title}

    resume_text = candidate_object.get("resume_text")
    if not resume_text:
        # Fetch resume data (cached by @st.cache_data for 10 minutes)
        resume_text, resume_source = _fetch_best_resume(chat_id)
    
    # Fetch history data (cached by @st.cache_data for 5 minutes)
    if not record_exists:
        history_lines = _fetch_history(chat_id)
        history_text = "\n".join([
            f"{item.get('type', 'unknown')}: {item.get('message', '')}"
            for item in history_lines
        ])
    else:
        history_lines = candidate_object.get("history")
        history_text = "\n".join([
            f"{item.get('type', 'unknown')}: {item.get('message', '')}"
            for item in history_lines
        ])
    
    if not record_exists:
        # init chat
        init_chat(chat_id, job_title, resume_text, history_lines)

    # === UI Rendering Phase (display data in expanders) ===
    # Resume expanders - now filled with cached data
    with st.expander("ç®€å†ä¿¡æ¯", expanded=bool(resume_text)):
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ç®€å†æ¥æº", resume_source)
        with col2:
            if st.button("ğŸ”„ åˆ·æ–°ç®€å†", key=f"refresh_resume_{chat_id}"):
                # Clear Streamlit cache and reload
                _fetch_online_resume.clear()
                _fetch_full_resume.clear()
                st.rerun()
        
        if resume_text:
            st.text_area("ç®€å†å†…å®¹", value=resume_text, height=300, key=f"resume_display_{chat_id}")
        else:
            st.warning("æš‚æ— ç®€å†æ•°æ®")
    
    # History expander - now filled with fetched data
    render_history_section(history_lines)

    # === Scoring Section (user-triggered) ===
    st.subheader("è‡ªåŠ¨è¯„åˆ†")

    # Display analysis results
    # analysis_result = st.session_state.get(SessionKeys.ANALYSIS_RESULTS, {}).get(chat_id)
    analysis_result = candidate_object.get("scores")
    if analysis_result:
        cols = st.columns(4)
        cols[0].metric("æŠ€èƒ½åŒ¹é…", analysis_result.get("skill"))
        cols[1].metric("åˆ›ä¸šå¥‘åˆ", analysis_result.get("startup_fit"))
        cols[2].metric("åŠ å…¥æ„æ„¿", analysis_result.get("willingness"))
        cols[3].metric("ç»¼åˆè¯„åˆ†", analysis_result.get("overall"), help='1-10åˆ†, å¦‚æœéœ€è¦è°ƒæ•´è¯„åˆ†ï¼Œè¯·ä¿®æ”¹åŠ©æ‰‹é…ç½®')
        st.markdown(f"**åˆ†ææ€»ç»“ï¼š** {analysis_result.get('summary', 'â€”')}")

    else:
        assistant_id = st.session_state.get(SessionKeys.SELECTED_ASSISTANT_ID)
        analysis_result = _analyze_candidate(chat_id, assistant_id, history_lines)
        update_candidate_object(chat_id, {"scores": analysis_result})
        st.rerun()

    # === Message Section (user-triggered) ===
    st.subheader("ç”Ÿæˆæ¶ˆæ¯")
    message_state = st.session_state.setdefault(SessionKeys.GENERATED_MESSAGES, {})
    draft = message_state.get(chat_id, "")
    draft_message = st.empty()
    draft = draft_message.text_area("æ¶ˆæ¯å†…å®¹", value=draft, height=180, key=f"message_draft_{chat_id}")
    col_generate, col_send = st.columns(2)
    # Generate button
    if col_generate.button("ç”Ÿæˆå»ºè®®", key=f"generate_msg_{chat_id}", disabled=bool(draft)):
        analysis_result = st.session_state.get(SessionKeys.ANALYSIS_RESULTS, {}).get(chat_id) or \
            _analyze_candidate(chat_id, selected_job, resume_text, history_text)
        assistant_id = st.session_state.get(SessionKeys.SELECTED_ASSISTANT_ID)
        # candidate_summary = (selected_dialog or {}).get("text", "")

        payload = {
            "chat_id": chat_id,
            "prompt": draft or "",
            "assistant_id": assistant_id,
            "chat_history": history_lines,
            "job_info": selected_job,
            # "candidate_summary": candidate_summary,
            "candidate_resume": resume_text,
            "analysis": analysis_result,
            "purpose": "chat",
        }

        with st.spinner("ç”Ÿæˆä¸­..."):
            ok, payload = call_api(
                "POST", "/assistant/generate-message",
                json=payload,
            )
            message = payload if ok else None
        if message:
            message_state[chat_id] = message
            st.success("ç”Ÿæˆå®Œæˆï¼")
            draft_message.text_area("æ¶ˆæ¯å†…å®¹", value=message, height=180)
            st.rerun()
        else:
            st.error(f"ç”Ÿæˆå¤±è´¥: {payload}")
    # Send button
    if col_send.button("å‘é€æ¶ˆæ¯", key=f"send_msg_{chat_id}"):
        content = draft.strip()
        if not content:
            st.warning("æ¶ˆæ¯å†…å®¹ä¸èƒ½ä¸ºç©º")
        else:
            with st.spinner("å‘é€ä¸­..."):
                ok, payload = call_api(
                    "POST",
                    f"/chat/{chat_id}/send",
                    json={"message": content},
                )
                success = ok
            if success:
                st.success("æ¶ˆæ¯å·²å‘é€")
                message_state[chat_id] = content
            else:
                st.error("å‘é€å¤±è´¥")

if __name__ == "__main__":
    main()
