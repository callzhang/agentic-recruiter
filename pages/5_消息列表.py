"""Enhanced message console with resume viewing, scoring, and AI drafting."""
from __future__ import annotations
import time
from pathlib import Path
from typing import Any, Dict, List, Optional

import streamlit as st

from streamlit_shared import call_api, ensure_state, sidebar_controls, SessionKeys, get_selected_job

COMPANY_MD_PATH = Path("config/company.md")
DEFAULT_HISTORY_LIMIT = 10

# ---------------------------------------------------------------------------
# Data loaders and helpers
# ---------------------------------------------------------------------------



@st.cache_data(ttl=600, show_spinner="è·å–æ¶ˆæ¯åˆ—è¡¨ä¸­...")
def _get_dialogs(limit: int, tab: str = 'æ–°æ‹›å‘¼', status: str = 'æœªè¯»', job_title: str = 'å…¨éƒ¨') -> List[Dict[str, Any]]:
    """Cached message fetching - depends only on inputs, not session state."""
    params = {
        "limit": limit,
        "tab": tab,
        "status": status,
        "job_title": job_title
    }
    ok, payload = call_api("GET", "/chat/dialogs", params=params)
    if not ok:
        raise ValueError(f"è·å–æ¶ˆæ¯åˆ—è¡¨å¤±è´¥: {payload}")
    if not isinstance(payload, list):
        raise ValueError("API è¿”å›çš„æ¶ˆæ¯æ ¼å¼ä¸ç¬¦åˆé¢„æœŸ") 
    return payload

@st.cache_data(ttl=300, show_spinner="è·å–ç®€å†ä¸­...")
def _fetch_resume(chat_id: str, endpoint: str) -> Optional[Dict[str, Any]]:
    """Fetch resume data with Streamlit caching."""
    ok, payload = call_api("POST", endpoint, json={"chat_id": chat_id})
    if not ok or not isinstance(payload, dict):
        # Don't cache errors - raise exception to skip caching
        raise ValueError(f"è·å–ç®€å†å¤±è´¥: {payload}")
    return payload


@st.cache_data(ttl=300, show_spinner="è·å–èŠå¤©è®°å½•ä¸­...")
def _fetch_history(chat_id: str) -> List[str]:
    """Fetch chat history with Streamlit caching."""
    ok, payload = call_api("GET", f"/chat/{chat_id}/messages")
    if not ok or not isinstance(payload, list):
        raise ValueError(f"è·å–èŠå¤©è®°å½•å¤±è´¥: {payload}")
    return payload



def _fetch_best_resume(chat_id: str) -> tuple[str, str]:
    """
    Fetch best available resume (full resume preferred, online as fallback).
    
    Cached for 10 minutes to improve performance.
    
    Returns:
        tuple[str, str]: (resume_text, source) where source is "é™„ä»¶ç®€å†" or "åœ¨çº¿ç®€å†"
    """
    # Step 1: Try full resume first
    try:
        if check_full_resume(chat_id):
            full_payload = _fetch_full_resume(chat_id)
            resume_text = full_payload.get("text", "")
            if resume_text:
                return resume_text, "é™„ä»¶ç®€å†"
    except Exception:
        pass  # Silently fall through to online resume
    
    # Step 2: Fallback to online resume
    try:
        online_payload = _fetch_online_resume(chat_id)
        resume_text = online_payload.get("text", "")
        if resume_text:
            return resume_text, "åœ¨çº¿ç®€å†"
    except Exception:
        pass  # No resume available
    
    return None, "æ— "

@st.cache_data(ttl=300, show_spinner="æ£€æŸ¥ç®€å†ä¸­...")
def check_full_resume(chat_id: str) -> bool:
    """Check if full resume is available."""
    ok, available = call_api("POST", "/resume/check_full_resume_available", json={"chat_id": chat_id})
    return ok and available

@st.cache_data(show_spinner="è·å–ç®€å†ä¸­...")
def _fetch_full_resume(chat_id: str) -> Dict[str, Any]:
    """Fetch full resume with Streamlit caching."""
    ok, payload = call_api("POST", "/resume/view_full", json={"chat_id": chat_id})
    if not ok:
        raise ValueError(f"API è°ƒç”¨å¤±è´¥")
    if not isinstance(payload, dict):
        raise ValueError(f"å“åº”æ ¼å¼é”™è¯¯: {payload}")
    return payload


@st.cache_data(show_spinner="è·å–åœ¨çº¿ç®€å†ä¸­...")
def _fetch_online_resume(chat_id: str) -> Dict[str, Any]:
    """Fetch online resume with Streamlit caching."""
    ok, payload = call_api("POST", "/resume/online", json={"chat_id": chat_id})
    if not ok:
        raise ValueError(f"API è°ƒç”¨å¤±è´¥")
    if not isinstance(payload, dict):
        raise ValueError(f"å“åº”æ ¼å¼é”™è¯¯: {payload}")
    return payload



# ---------------------------------------------------------------------------
# UI components
# ---------------------------------------------------------------------------

def render_resume_section(
    title: str,
    chat_id: str,
    endpoint: str,
    cache_key: str,
    request_when_missing: bool = False,
    check_endpoint: Optional[str] = None,
) -> str:
    """
    æ¸²æŸ“ç®€å†å±•ç¤ºåŒºå—ï¼Œæ”¯æŒåŠ è½½ã€åˆ·æ–°ã€å¯é€‰çš„å¯ç”¨æ€§æ£€æŸ¥å’Œç®€å†è¯·æ±‚ã€‚

    å‚æ•°:
        title (str): å±•å¼€åŒºå—æ ‡é¢˜ã€‚
        chat_id (str): èŠå¤©ä¼šè¯IDã€‚
        endpoint (str): è·å–ç®€å†çš„APIç«¯ç‚¹ã€‚
        cache_key (str): ç”¨äºç¼“å­˜çš„å”¯ä¸€é”®ã€‚
        request_when_missing (bool): è‹¥ç®€å†ä¸å¯ç”¨æ—¶æ˜¯å¦å…è®¸è¯·æ±‚ç®€å†ã€‚
        check_endpoint (Optional[str]): æ£€æŸ¥ç®€å†å¯ç”¨æ€§çš„APIç«¯ç‚¹ï¼ˆå¯é€‰ï¼‰ã€‚

    è¿”å›:
        str: ç®€å†æ–‡æœ¬å†…å®¹ï¼ˆå¦‚æœ‰ï¼‰ï¼Œå¦åˆ™ä¸ºç©ºå­—ç¬¦ä¸²ã€‚
    """
    text = ""
    load_state_key = f"loaded_{cache_key}_{chat_id}"
    with st.expander(title, expanded=False):
        cols = st.columns([1, 1, 3])
        if cols[0].button("åŠ è½½", key=f"load_{cache_key}_{chat_id}"):
            st.session_state[load_state_key] = True

        load_state = st.session_state.get(load_state_key, False)
        if not load_state:
            st.caption("ç‚¹å‡»â€œåŠ è½½â€ä»¥è·å–å†…å®¹ã€‚")
            return text

        if st.session_state[load_state_key]:
            try:
                data = _fetch_resume(chat_id, endpoint)
                text = data.get("text") or data.get("content") or ""
                if text:
                    st.text_area("å†…å®¹", value=text, height=300)
                else:
                    st.info("æš‚æ— å¯æ˜¾ç¤ºçš„ç®€å†æ–‡æœ¬ã€‚")
            except Exception as e:
                st.warning(f"æ— æ³•è·å–ç®€å†: {str(e)}")
        return text


def render_history_section(history: List[Dict[str, Any]]) -> None:
    st.subheader("èŠå¤©è®°å½•")
    formatted_history = []
    for item in history:
        type_emoji = "ğŸ‘¤" if item.get('type') == 'candidate' else "ğŸ¢"
        status_emoji = "âœ…" if item.get('status') == 'processed' else "â³" if item.get('status') else "â“"
        formatted_item = {
            'ç±»å‹': f"{type_emoji} {'å€™é€‰äºº' if item.get('type') == 'candidate' else 'HR'}",
            'æ—¶é—´': item.get('timestamp', ''),
            'æ¶ˆæ¯å†…å®¹': item.get('message', ''),
            'çŠ¶æ€': f"{status_emoji} {item.get('status') if item.get('status') else 'æœªå¤„ç†'}"
        }
        formatted_history.append(formatted_item)
    import pandas as pd
    df = pd.DataFrame(history)
    st.dataframe(
        df, 
        width="stretch", 
        hide_index=True,
        column_config={
            "ç±»å‹": st.column_config.TextColumn("ç±»å‹", width="small"),
            "æ—¶é—´": st.column_config.TextColumn("æ—¶é—´", width="medium"),
            "æ¶ˆæ¯å†…å®¹": st.column_config.TextColumn("æ¶ˆæ¯å†…å®¹", width="large"),
            "çŠ¶æ€": st.column_config.TextColumn("çŠ¶æ€", width="small")
        }
    )


@st.cache_data(show_spinner="åˆ†æä¸­...")
def _analyze_candidate(chat_id: str, assistant_id: str, history: list[dict]) -> Dict[str, Any]:
    context = {
        "chat_id": chat_id,
        "assistant_id": assistant_id,
        "chat_history": history,
        "purpose": "analyze",
        # "instruction": "è¯·æ ¹æ®å²—ä½æè¿°ï¼Œå¯¹å€™é€‰äººçš„ç®€å†è¿›è¡Œæ‰“åˆ†ï¼Œç”¨äºå†³å®šæ˜¯å¦ç»§ç»­æ¨è¿›ã€‚",
    }
    ok, generated_message = call_api(
        "POST", "/assistant/generate-message",
        json=context
        )
    if ok:
        get_thread_messages.clear()
        st.session_state.setdefault(SessionKeys.ANALYSIS_RESULTS, {})[chat_id] = generated_message
        return generated_message
    else:
        raise ValueError(f"æ— æ³•è§£æè¯„åˆ†ç»“æœ: {generated_message}")

@st.cache_data(show_spinner="è·å–å€™é€‰äººä¸­...")
def get_candidate_by_id(chat_id: str) -> Dict[str, Any]:
    """Get candidate by ID."""
    ok, payload = call_api("GET", f"/candidate/{chat_id}")
    if not ok or not isinstance(payload, dict):
        raise ValueError(f"è·å–å€™é€‰äººå¤±è´¥: {payload}")
    assert payload.get('resume_text'), "è·å–å€™é€‰äººå¤±è´¥: æ²¡æœ‰ç®€å†æ•°æ®"
    return payload


def init_chat(chat_id: str, name: str, job_info: dict, resume_text: str, chat_history: list[dict]) -> bool:
    """Init chat."""
    ok, payload = call_api("POST", "/thread/init-chat", json={
        "name": name,
        "chat_id": chat_id,
        "job_info": job_info,
        "resume_text": resume_text,
        "chat_history": chat_history
    })
    get_candidate_by_id.clear()
    return ok


@st.cache_data(show_spinner="è·å–threadèŠå¤©è®°å½•ä¸­...")
def get_thread_messages(thread_id: str) -> list[dict]:
    """Get thread messages."""
    ok, payload = call_api("GET", f"/thread/{thread_id}/messages")
    if not ok or not isinstance(payload, list):
        raise ValueError(f"è·å–èŠå¤©è®°å½•å¤±è´¥: {payload}")
    return payload


def generate_message(chat_id: str, assistant_id: str, history: list[dict]) -> Dict[str, Any]:
    """Generate message."""
    ok, generated_message = call_api("POST", "/assistant/generate-message", json={
        "chat_id": chat_id,
        "assistant_id": assistant_id,
        "chat_history": history,
        "purpose": "chat"
    })
    return generated_message

def stream_message(message: str) -> None:
    """Stream message."""
    for w in message:
        yield w
        time.sleep(0.02)

def send_message_and_request_full_resume(chat_id: str, message: str) -> None:
    """Send message and request full resume. API now returns bool instead of success/details dict."""
    if not message:
        st.warning("æ¶ˆæ¯å†…å®¹ä¸èƒ½ä¸ºç©º")
        return
    
    # Send message
    try:
        with st.spinner("å‘é€ä¸­..."):
            ok, result = call_api("POST", f"/chat/{chat_id}/send", json={"message": message})
            if ok and result is True:
                st.success("æ¶ˆæ¯å‘é€æˆåŠŸ")
            else:
                st.error(f"æ¶ˆæ¯å‘é€å¤±è´¥: {result}")
    except Exception as e:
        st.error(f"å‘é€æ¶ˆæ¯æ—¶å‡ºé”™: {str(e)}")
    
    # Request resume
    try:
        with st.spinner("è¯·æ±‚å®Œæ•´ç®€å†ä¸­..."):
            ok, result = call_api("POST", "/resume/request", json={"chat_id": chat_id})
            if ok and result is True:
                st.success("ç®€å†è¯·æ±‚å·²å‘é€")
            else:
                st.error(f"ç®€å†è¯·æ±‚å¤±è´¥: {result}")
    except Exception as e:
        st.error(f"è¯·æ±‚ç®€å†æ—¶å‡ºé”™: {str(e)}")

# ---------------------------------------------------------------------------
# Main entrypoint
# ---------------------------------------------------------------------------

def main() -> None:
    st.title("æ¶ˆæ¯åˆ—è¡¨")
    ensure_state()
    sidebar_controls(include_config_path=False, include_job_selector=True)
    limit = st.sidebar.slider("æ¯æ¬¡è·å–å¯¹è¯æ•°é‡", min_value=5, max_value=100, value=30, step=5)
    assistant_id = st.session_state.get(SessionKeys.SELECTED_ASSISTANT_ID)
    # Sync job selection
    selected_job_idx = st.session_state.get(SessionKeys.SELECTED_JOB_INDEX, 0)
    job_info = get_selected_job(selected_job_idx)
    job_title = job_info.get("position")
    # === Filter Controls ===
    candidate_type = st.radio("Candidate type", options=['æ–°æ‹›å‘¼', 'æ²Ÿé€šä¸­', 'ç‰›äººå·²è¯»æœªå›'], index=0, horizontal=True)
    if candidate_type == 'æ–°æ‹›å‘¼':
        tab_filter = 'æ–°æ‹›å‘¼'
        status_filter = 'æœªè¯»'
    elif candidate_type == 'æ²Ÿé€šä¸­':
        tab_filter = 'æ²Ÿé€šä¸­'
        status_filter = 'æœªè¯»'
    else:
        tab_filter = 'æ²Ÿé€šä¸­'
        status_filter = 'ç‰›äººå·²è¯»æœªå›'
    
    
    # dialogs
    dialogs = _get_dialogs(limit, tab_filter, status_filter, job_title)
    if not dialogs:
        st.info("æš‚æ— èŠå¤©å¯¹è¯æ•°æ®ã€‚ã€‚ã€‚")
        return

    # å¯¹è¯ä¸‹æ‹‰æ¡†
    col_select, col_refresh = st.columns([9, 1])
    cached_chat_id = st.session_state.get(SessionKeys.SELECTED_CHAT_ID)
    if 'chat_selector' not in st.session_state:
        st.session_state["chat_selector"] = cached_chat_id

    # get chat_id
    chat_id = col_select.selectbox(
        'None',
        options=[row["id"] for row in dialogs],
        format_func=lambda cid: next(
            (f"{row['name']}({row['job_title']}): {row['text']}" for row in dialogs if row['id'] == cid),
            cid,
        ),
        key=f"chat_selector",
        index=None, #When you pass index=None, you tell Streamlit â€œdonâ€™t fix an index, use whatever is in session_state,â€ allowing your explicit state update to drive the selection.
        label_visibility="collapsed",
    )
    
    # Update session state when selection changes
    if chat_id and chat_id != cached_chat_id:
        st.session_state[SessionKeys.SELECTED_CHAT_ID] = chat_id
    # é€‰ä¸­å¯¹è¯
    selected_dialog = next((row for row in dialogs if row['id'] == chat_id), None)
    if col_refresh.button("ğŸ”„", key="refresh_messages_main"):
        _get_dialogs.clear()
        st.rerun()

    # Null safety check
    if not selected_dialog:
        st.warning("æœªèƒ½æ‰¾åˆ°é€‰ä¸­çš„å€™é€‰äººï¼Œè¯·åˆ·æ–°åˆ—è¡¨é‡è¯•")
        return

    # === Data Fetching Phase (upfront, cached by Streamlit) ===
    try:
        record_exists =False
        candidate_object = get_candidate_by_id(chat_id)
        record_exists = True
    except Exception as e:
        # cannot create a new candidate without resume_text
        candidate_object = {
            "name": selected_dialog.get("name"), 
            "job_applied": job_title}

    resume_text = candidate_object.get("resume_text")
    full_resume = candidate_object.get("full_resume")
    if not resume_text:
        # Fetch resume data (cached by @st.cache_data for 10 minutes)
        resume_text, resume_source = _fetch_best_resume(chat_id)
        # append_resume_to_thread_and_store(chat_id, resume_text, resume_source)
    else:
        if full_resume:
            resume_source = "é™„ä»¶ç®€å†"
        else:
            resume_source = "åœ¨çº¿ç®€å†"
    assert resume_text, "æ— æ³•è·å–ç®€å†æ•°æ®"
    
   
    # Resume expanders - now filled with cached data
    with st.expander("ç®€å†ä¿¡æ¯", expanded=bool(resume_text)):
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ç®€å†æ¥æº", resume_source)
        with col2:
            if st.button("ğŸ”„ åˆ·æ–°ç®€å†", key=f"refresh_resume_{chat_id}"):
                # Clear Streamlit cache and reload
                _fetch_online_resume.clear()
                _fetch_full_resume.clear()
                st.rerun()
        
        if resume_text:
            st.text_area("ç®€å†å†…å®¹", value=resume_text, height=300, key=f"resume_display_{chat_id}")
        else:
            st.warning("æš‚æ— ç®€å†æ•°æ®")
    
    
    # Fetch history data (cached by @st.cache_data for 5 minutes)
    chat_messages = _fetch_history(chat_id)
    render_history_section(chat_messages)

    # åˆ›å»ºå¯¹è±¡
    if not record_exists:
        # init chat
        suceess = init_chat(chat_id, selected_dialog.get("name"), job_info, resume_text, chat_messages)
        if not suceess:
            st.error("åˆå§‹åŒ–èŠå¤©å¤±è´¥")
            return

    # === Scoring Section (user-triggered) ===
    st.subheader("è‡ªåŠ¨è¯„åˆ†")

    # Display analysis results
    # analysis_result = st.session_state.get(SessionKeys.ANALYSIS_RESULTS, {}).get(chat_id)
    analysis_result = candidate_object.get("analysis") or st.session_state.get(SessionKeys.ANALYSIS_RESULTS, {}).get(chat_id)
    if analysis_result:
        cols = st.columns(4)
        cols[0].metric("æŠ€èƒ½åŒ¹é…", analysis_result.get("skill"))
        cols[1].metric("åˆ›ä¸šå¥‘åˆ", analysis_result.get("startup_fit"))
        cols[2].metric("åŠ å…¥æ„æ„¿", analysis_result.get("willingness"))
        cols[3].metric("ç»¼åˆè¯„åˆ†", analysis_result.get("overall"), help='1-10åˆ†, å¦‚æœéœ€è¦è°ƒæ•´è¯„åˆ†ï¼Œè¯·ä¿®æ”¹åŠ©æ‰‹é…ç½®')
        st.text_area("åˆ†ææ€»ç»“", value=analysis_result.get('summary', 'â€”'), height=180, key=f"analysis_summary_{chat_id}")
    else:
        analysis_result = _analyze_candidate(chat_id, assistant_id, chat_messages)
        st.session_state.setdefault(SessionKeys.ANALYSIS_RESULTS, {})[chat_id] = analysis_result
        st.rerun()

    # === Message Section (user-triggered) ===
    st.subheader("ç”Ÿæˆæ¶ˆæ¯")
    followup_message = st.session_state.setdefault(SessionKeys.GENERATED_MESSAGES, {}).get(chat_id)
    if not followup_message:
        if st.button("ç”Ÿæˆå»ºè®®", key=f"generate_msg_{chat_id}", disabled=bool(followup_message)):
            followup_message = generate_message(chat_id, assistant_id, chat_messages)
            st.write_stream(stream_message(followup_message))
            st.session_state[SessionKeys.GENERATED_MESSAGES][chat_id] = followup_message
        else:
            st.warning("è¯·å…ˆç”Ÿæˆæ¶ˆæ¯")
    else:
        st.text_area("æ¶ˆæ¯å†…å®¹", value=followup_message, height=180, key=f"message_draft_{chat_id}")
    # Send button
    if st.button("å‘é€æ¶ˆæ¯", key=f"send_msg_{chat_id}", disabled=not bool(followup_message)):
        send_message_and_request_full_resume(chat_id, followup_message)

    # pass and next button
    current_index = next(i for i, row in enumerate(dialogs) if row['id'] == cached_chat_id)
    if st.button('Next'):
        next_index = current_index + 1
        next_chat_id = dialogs[next_index]["id"]
        st.session_state[SessionKeys.SELECTED_CHAT_ID] = next_chat_id
        del st.session_state["chat_selector"] 
        st.rerun()

    if st.button("PASSï¼ŒæŸ¥çœ‹ä¸‹ä¸€ä¸ªå€™é€‰äºº", key=f"pass_and_next_{chat_id}"):
        """Move to the next candidate in the dialog list."""
        next_index = current_index + 1
        if next_index >= len(dialogs):
            # fetch more candidates
            pass

        next_chat_id = dialogs[next_index]["id"]
        st.session_state[SessionKeys.SELECTED_CHAT_ID] = next_chat_id
        del st.session_state["chat_selector"] 
        # update the candidate with stage=PASS
        ok, payload = call_api("POST", "/candidate/discard", json={"chat_id": chat_id, "stage": "PASS"})
        if not ok:
            st.error(f"æ›´æ–°å€™é€‰äººé˜¶æ®µå¤±è´¥: {payload}")
            time.sleep(3)
        else:
            st.success(f"å·²æ›´æ–°å€™é€‰äººé˜¶æ®µ: {payload}")
        
        st.success(f"å·²åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªå€™é€‰äºº: {dialogs[next_index].get('name', 'Unknown')}ï¼ˆ{next_chat_id}ï¼‰")
        
        st.rerun() #todo: ç°åœ¨æ— æ³•è‡ªåŠ¨è·³è½¬åˆ°ä¸‹ä¸€ä¸ªå€™é€‰äººï¼Œéœ€è¦æ‰‹åŠ¨åˆ·æ–°
if __name__ == "__main__":
    main()
