"""Zilliz/Milvus-backed QA and candidate interaction store integration."""
from __future__ import annotations

import json
from datetime import datetime
from typing import Any, Dict, Iterable, List, Optional

from pymilvus import (
    Collection,
    CollectionSchema,
    DataType,
    FieldSchema,
    SearchResult,
    connections,
    utility,
)
# Note: Milvus embedding functions are not supported in current Zilliz Cloud version
# Keeping manual embedding generation for now
EMBEDDING_FUNCTION_AVAILABLE = False

from .global_logger import logger
from .config import settings

fields = [
    # Primary key - auto-generated by Milvus
    FieldSchema(name="candidate_id", dtype=DataType.VARCHAR, max_length=64, is_primary=True, auto_id=True),
    FieldSchema(name="resume_vector", dtype=DataType.FLOAT_VECTOR, dim=settings.ZILLIZ_EMBEDDING_DIM),

    # UI chat_id - used for UI operations
    FieldSchema(name="chat_id", dtype=DataType.VARCHAR, max_length=100, nullable=True),

    # Basic candidate info
    FieldSchema(name="name", dtype=DataType.VARCHAR, max_length=200, nullable=True),
    FieldSchema(name="job_applied", dtype=DataType.VARCHAR, max_length=128, nullable=True),
    FieldSchema(name="last_message", dtype=DataType.VARCHAR, max_length=2048, nullable=True),
    FieldSchema(name="resume_text", dtype=DataType.VARCHAR, max_length=25000, nullable=True),
    FieldSchema(name="metadata", dtype=DataType.JSON, nullable=True),
    FieldSchema(name="updated_at", dtype=DataType.VARCHAR, max_length=64, nullable=True),
    FieldSchema(name="analysis", dtype=DataType.JSON, nullable=True),

    # Additional fields
    FieldSchema(name="stage", dtype=DataType.VARCHAR, max_length=20, nullable=True),
    FieldSchema(name="full_resume", dtype=DataType.VARCHAR, max_length=10000, nullable=True),
    FieldSchema(name="thread_id", dtype=DataType.VARCHAR, max_length=100, nullable=True),
]

# List of all field names except "resume_vector"
_all_fields = [f.name for f in fields if f.dtype != DataType.FLOAT_VECTOR]


class CandidateStore:
    def __init__(
        self,
        endpoint: str,
        collection_name: str = settings.ZILLIZ_COLLECTION_NAME,
        embedding_dim: int = settings.ZILLIZ_EMBEDDING_DIM,
        similarity_top_k: int = settings.ZILLIZ_SIMILARITY_TOP_K,
        token: Optional[str] = None,
        user: Optional[str] = None,
        password: Optional[str] = None,
        secure: Optional[bool] = None,
    ) -> None:
        self.endpoint = endpoint
        self.token = token
        self.user = user
        self.password = password
        self.collection_name = collection_name
        self.embedding_dim = embedding_dim
        self.similarity_top_k = similarity_top_k
        self.secure = secure if secure is not None else endpoint.startswith("https://")
        self.collection: Optional[Collection] = None
        self.embedding_function = None
        self.enabled = self._connect_and_prepare()

    # ------------------------------------------------------------------
    # Connection helpers
    # ------------------------------------------------------------------
    def _connect_and_prepare(self) -> bool:
        try:
            logger.info("Connecting to Zilliz endpoint %s", self.endpoint)
            connect_args = {"alias": "default"}
            if self.token:
                connect_args.update({
                    "uri": self.endpoint,
                    "token": self.token,
                    "secure": self.secure,
                })
            else:
                connect_args.update(
                    {
                        "uri": self.endpoint,
                        "user": self.user,
                        "password": self.password,
                        "secure": self.secure,
                    }
                )
            connections.connect(**connect_args)
            
            # Note: Embedding functions not supported in current Zilliz version
            # Manual embedding generation is handled in assistant_actions.py
            
            self.collection = self._ensure_candidate_collection(self.collection_name)
            return True
        except Exception as exc:
            logger.exception("Failed to connect to Zilliz: %s", exc)
            return False


    def _ensure_candidate_collection(self, name: str) -> Collection:
        if not utility.has_collection(name):
            logger.info("Creating candidate collection %s", name)
            schema = CollectionSchema(fields, description="Candidate profiles")
            collection = Collection(name=name, schema=schema)
            index_params = {
                "index_type": "AUTOINDEX",
                "metric_type": "IP",
                "params": {},
            }
            collection.create_index(field_name="resume_vector", index_params=index_params)
            collection.create_index(field_name="chat_id")
            collection.create_index(field_name="thread_id")
            collection.create_index(field_name="stage")
            collection.load()
            logger.info("âœ… Created and loaded collection %s", name)
        else:
            logger.info("Collection %s already exists, loading it", name)
            collection = Collection(name)
            collection.load()
        return collection


    # ------------------------------------------------------------------
    # Candidate operations
    # ------------------------------------------------------------------
    def insert_candidate(
        self,
        *,
        chat_id: Optional[str] = None,
        name: str,
        job_applied: str,
        resume_text: str,
        resume_vector: Iterable[float],
        thread_id: str,
        last_message: str = None,
        analysis: Optional[Dict[str, Any]] = None,
        metadata: Optional[Dict[str, Any]] = None,
        stage: Optional[str] = None,
        full_resume: Optional[str] = None,
    ) -> bool:
        """Insert a new candidate record.
        
        Args:
            resume_vector: the resume vector generated by the embedding model.
            resume_text: Will be truncated to 8000 characters if longer.
        """
        if not self.enabled or not self.collection:
            return False
        
        # Prepare data for insert (don't include candidate_id - auto-generated)
        data = {
            "chat_id": chat_id,  # Can be None for recommend candidates
            "name": name,
            "job_applied": job_applied,
            "last_message": last_message,
            "resume_text": resume_text,
            "analysis": analysis or {},
            "metadata": metadata or {},
            "updated_at": datetime.now().isoformat(),
            "stage": stage,
            "full_resume": full_resume,
            "thread_id": thread_id,
            'resume_vector': resume_vector, 
        }
        
        # Remove None values except for nullable fields (chat_id can be None)
        # Keep chat_id even if None, as it's a valid nullable field
        data = {k: v for k, v in data.items() if v is not None or k == "chat_id"}
        
        try:
            self.collection.insert([data])
            self.collection.flush()
            return True
        except Exception as exc:
            logger.exception("Failed to insert candidate %s: %s", chat_id, exc)
            return False

    def update_candidate(
        self,
        candidate_id: str,
        **kwargs,
    ) -> bool:
        """update candidate data using Milvus native upsert."""
        
        # Only include fields that are not None
        data = {k: v for k, v in kwargs.items() if v is not None}
        data['updated_at'] = datetime.now().isoformat()
        data['candidate_id'] = candidate_id
        
        try:
            # Use Milvus native upsert - it handles insert/update automatically
            self.collection.upsert([data], partial_update=True)
            self.collection.flush()
            return True
        except Exception as exc:
            logger.exception("Failed to update candidate %s: %s", candidate_id, exc)
            return False


    def search_candidates(self, resume_vector: List[float], limit: Optional[int] = 1, similarity_threshold = 0.9) -> List[Dict[str, Any]]:
        """Search for similar candidates by resume vector."""
        if not self.enabled or not self.collection:
            return []
        limit = limit or self.similarity_top_k
        search_params = {
            "metric_type": "IP",
            "params": {"ef": 32},
        }
        results: List[SearchResult] = self.collection.search(
            data=[resume_vector],
            anns_field="resume_vector",
            limit=limit,
            param=search_params,
            output_fields=_all_fields,
        )
        hits = [result['entity'] for result in results[0][:limit] if result.score > similarity_threshold]
        
        if hits:
            return hits[0]
        else:
            return None


    def get_candidate_by_id(self, chat_id = None, thread_id = None, candidate_id = None, fields = _all_fields) -> Optional[Dict[str, Any]]:
        """Retrieve a single candidate record by chat_id."""
        assert chat_id or candidate_id or thread_id, "chat_id or candidate_id or thread_id is required"
        if fields is None:
            fields = _all_fields
        if chat_id:
            expr = f"chat_id == {json.dumps(chat_id)}"
        elif candidate_id:
            expr = f"candidate_id == {json.dumps(candidate_id)}"
        elif thread_id:
            expr = f"thread_id == {json.dumps(thread_id)}"
        else:
            raise ValueError("chat_id or candidate_id is required")

        results: List[Dict[str, Any]] = self.collection.query(
            expr=expr,
            output_fields=fields,
            limit=1,
        )

        if not results:
            return None
        return results[0]

    def upsert_candidate(self, **kwargs) -> bool:
        """Insert or update candidate information in the store.
        
        This is a convenience method that checks if candidate exists and routes to
        insert_candidate() or update_candidate() accordingly.
        
        Embedding generation and resume truncation are handled by insert_candidate().
        
        Args:
            **kwargs: Candidate data
        Returns:
            bool: True if successful, False otherwise
        """
        # Check if candidate exists by candidate_id, chat_id, or thread_id (conversation_id)
        candidate_id = kwargs.get("candidate_id")
        chat_id = kwargs.get("chat_id")
        thread_id = kwargs.get("thread_id")
        if chat_id or candidate_id or thread_id:
            existing_candidate = self.get_candidate_by_id(chat_id=chat_id, candidate_id=candidate_id, thread_id=thread_id)
        else:
            existing_candidate = None

        if not existing_candidate:
            # Create new candidate - insert_candidate handles embedding and truncation
            # required: 'name', 'job_applied', 'resume_text', and 'resume_vector'
            logger.info("Creating new candidate: %s", kwargs['name'])
            return self.insert_candidate(**kwargs)
        else:
            # Update existing candidate
            logger.info("Updating existing candidate")
            existing_candidate.update(kwargs)
            return self.update_candidate(**existing_candidate)


# ------------------------------------------------------------------
# Candidate record persistence - Module-level convenience functions
# ------------------------------------------------------------------

# Create global instance with safe defaults
# Load configuration from environment or config file
def _create_candidate_store() -> CandidateStore:
    """Create candidate store instance with configuration."""
    from .config import settings
    
    # Use settings from config.py
    endpoint = settings.ZILLIZ_ENDPOINT
    user = settings.ZILLIZ_USER
    password = settings.ZILLIZ_PASSWORD
    collection_name = settings.ZILLIZ_COLLECTION_NAME
    embedding_dim = settings.ZILLIZ_EMBEDDING_DIM
    similarity_top_k = settings.ZILLIZ_SIMILARITY_TOP_K
    
    if not endpoint:
        logger.info("No Zilliz endpoint configured, candidate store will be disabled")
        endpoint = "http://localhost:19530"

    return CandidateStore(
        endpoint=endpoint,
        collection_name=collection_name,
        embedding_dim=embedding_dim,
        similarity_top_k=similarity_top_k,
        user=user if user else None,
        password=password if password else None,
    )

candidate_store = _create_candidate_store()

__all__ = ["candidate_store", "CandidateStore", "update_candidate_resume"]
