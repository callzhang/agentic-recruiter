"""Zilliz/Milvus-backed QA and candidate interaction store integration."""
from __future__ import annotations

from functools import lru_cache
import json
from datetime import datetime
from typing import Any, Dict, Iterable, List, Optional, Union
from pymilvus import (
    Collection,
    CollectionSchema,
    DataType,
    FieldSchema,
    SearchResult,
    connections,
    utility,
)

# Note: Milvus embedding functions are not supported in current Zilliz Cloud version
# Keeping manual embedding generation for now
EMBEDDING_FUNCTION_AVAILABLE = False

from .global_logger import logger
from .config import settings

fields = [
    # Primary key - auto-generated by Milvus
    FieldSchema(name="candidate_id", dtype=DataType.VARCHAR, max_length=64, is_primary=True, auto_id=True),
    FieldSchema(name="resume_vector", dtype=DataType.FLOAT_VECTOR, dim=settings.ZILLIZ_EMBEDDING_DIM),

    # UI chat_id - used for UI operations
    FieldSchema(name="chat_id", dtype=DataType.VARCHAR, max_length=100, nullable=True),

    # Basic candidate info
    FieldSchema(name="name", dtype=DataType.VARCHAR, max_length=200, nullable=True),
    FieldSchema(name="job_applied", dtype=DataType.VARCHAR, max_length=128, nullable=True),
    FieldSchema(name="last_message", dtype=DataType.VARCHAR, max_length=2048, nullable=True),
    FieldSchema(name="resume_text", dtype=DataType.VARCHAR, max_length=25000, nullable=True),
    FieldSchema(name="metadata", dtype=DataType.JSON, nullable=True),
    FieldSchema(name="updated_at", dtype=DataType.VARCHAR, max_length=64, nullable=True),
    FieldSchema(name="analysis", dtype=DataType.JSON, nullable=True),

    # Additional fields
    FieldSchema(name="stage", dtype=DataType.VARCHAR, max_length=20, nullable=True),
    FieldSchema(name="full_resume", dtype=DataType.VARCHAR, max_length=10000, nullable=True),
    FieldSchema(name="conversation_id", dtype=DataType.VARCHAR, max_length=100, nullable=True),
]

# List of all field names except "resume_vector"
_readable_fields = [f.name for f in fields if f.dtype != DataType.FLOAT_VECTOR]
_all_fields = [f.name for f in fields]

class CandidateStore:
    def __init__(
        self,
        endpoint: str,
        collection_name: str = settings.ZILLIZ_COLLECTION_NAME,
        embedding_dim: int = settings.ZILLIZ_EMBEDDING_DIM,
        similarity_top_k: int = settings.ZILLIZ_SIMILARITY_TOP_K,
        token: Optional[str] = None,
        user: Optional[str] = None,
        password: Optional[str] = None,
        secure: Optional[bool] = None,
    ) -> None:
        self.endpoint = endpoint
        self.token = token
        self.user = user
        self.password = password
        self.collection_name = collection_name
        self.embedding_dim = embedding_dim
        self.similarity_top_k = similarity_top_k
        self.secure = secure if secure is not None else endpoint.startswith("https://")
        self.collection: Optional[Collection] = None
        self.embedding_function = None
        self.enabled = self._connect_and_prepare()

    # ------------------------------------------------------------------
    # Connection helpers
    # ------------------------------------------------------------------
    def _connect_and_prepare(self) -> bool:
        try:
            logger.debug("Connecting to Zilliz endpoint %s", self.endpoint)
            connect_args = {"alias": "default"}
            if self.token:
                connect_args.update({
                    "uri": self.endpoint,
                    "token": self.token,
                    "secure": self.secure,
                })
            else:
                connect_args.update(
                    {
                        "uri": self.endpoint,
                        "user": self.user,
                        "password": self.password,
                        "secure": self.secure,
                    }
                )
            connections.connect(**connect_args)
            
            # Note: Embedding functions not supported in current Zilliz version
            # Manual embedding generation is handled in assistant_actions.py
            
            self.collection = self._ensure_candidate_collection(self.collection_name)
            return True
        except Exception as exc:
            logger.exception("Failed to connect to Zilliz: %s", exc)
            return False


    def _ensure_candidate_collection(self, name: str) -> Collection:
        if not utility.has_collection(name):
            logger.debug("Creating candidate collection %s", name)
            schema = CollectionSchema(fields, description="Candidate profiles")
            collection = Collection(name=name, schema=schema)
            index_params = {
                "index_type": "AUTOINDEX",
                "metric_type": "IP",
                "params": {},
            }
            collection.create_index(field_name="resume_vector", index_params=index_params)
            collection.create_index(field_name="chat_id")
            collection.create_index(field_name="conversation_id")
            collection.create_index(field_name="stage")
            collection.load()
            logger.info("âœ… Created and loaded collection %s", name)
        else:
            logger.debug("Collection %s already exists, loading it", name)
            collection = Collection(name)
            collection.load()
        return collection


    # ------------------------------------------------------------------
    # Candidate operations
    # ------------------------------------------------------------------
    def _insert_candidate(
        self,
        **kwargs: Dict[str, Any],
    ) -> bool:
        """Insert a new candidate record.
        
        Args:
            resume_vector: the resume vector generated by the embedding model.
            resume_text: Will be truncated to 25000 characters if longer (field max_length).
        """
        if not self.enabled or not self.collection:
            return None
        
        try:
            result = self.collection.insert([kwargs])
            self.collection.flush()
            return result.primary_keys[0]
        except Exception as exc:
            logger.exception("Failed to insert candidate %s: %s", kwargs['name'], exc)
            return None

    def _update_candidate(
        self,
        candidate_id: str,
        **kwargs,
    ) -> bool:
        """update candidate data using Milvus native upsert."""
        kwargs['candidate_id'] = candidate_id
        
        try:
            # Use Milvus native upsert - it handles insert/update automatically
            result = self.collection.upsert([kwargs], partial_update=True)
            self.collection.flush()
            return result.primary_keys[0]
        except Exception as exc:
            logger.exception("Failed to update candidate %s: %s", candidate_id, exc)
            return None


    def upsert_candidate(self, **kwargs) -> bool:
        """Insert or update candidate information in the store.
        
        This is a convenience method that checks if candidate exists and routes to
        insert_candidate() or update_candidate() accordingly.
        
        Automatically generates resume_vector embedding if not provided and resume_text is available.
        Truncates resume_text to 8000 characters if longer.
        
        Args:
            **kwargs: Candidate data
        Returns:
            bool: True if successful, False otherwise
        """
        # Check if candidate exists by candidate_id, chat_id, or conversation_id
        candidate_id = kwargs.get("candidate_id")
        chat_id = kwargs.get("chat_id")
        conversation_id = kwargs.get("conversation_id")
        if kwargs.get("resume_text"):
            kwargs['resume_text'] = kwargs['resume_text'][:8000]
        if kwargs.get("full_resume"):
            kwargs['full_resume'] = kwargs['full_resume'][:8000]
        if kwargs.get("analysis") and isinstance(kwargs['analysis'], str):
            kwargs['analysis'] = json.loads(kwargs['analysis'])
        if kwargs.get("metadata") and isinstance(kwargs['metadata'], str):
            kwargs['metadata'] = json.loads(kwargs['metadata'])
        kwargs['updated_at'] = datetime.now().isoformat()
        
        # Remove None values except for nullable fields (chat_id can be None)
        kwargs = {k:v for k, v in kwargs.items() if k in _all_fields}
        kwargs = {k: v.strip() if isinstance(v, str) else v for k, v in kwargs.items() if v or v == 0}

        if chat_id or candidate_id or conversation_id:
            # Collect identifiers
            identifiers = []
            if chat_id:
                identifiers.append(chat_id)
            if candidate_id:
                identifiers.append(candidate_id)
            if conversation_id:
                identifiers.append(conversation_id)
            
            # Query using get_candidates
            results = self.get_candidates(identifiers=identifiers, limit=1, fields=_all_fields)
            if not results:
                existing_candidate = None
                if candidate_id:
                    logger.error(f"Candidate not found: {identifiers}")
            else:
                existing_candidate = results[0]
        else:
            existing_candidate = None

        if not existing_candidate:
            # Create new candidate - need to generate embedding and truncate resume if needed
            resume_text = kwargs.get("resume_text")
            resume_vector = kwargs.get("resume_vector")
            
            # Generate embedding if not provided
            if not resume_vector and resume_text:
                resume_vector = get_embedding(resume_text)
                kwargs["resume_vector"] = resume_vector
            
            logger.debug(f"Creating new candidate: {kwargs['name']}-{kwargs['job_applied']}")
            pk = self._insert_candidate(**kwargs)
            if not pk:
                logger.error(f"Failed to create new candidate: {kwargs['name']}")
            return pk
        else:
            # Update existing candidate
            if kwargs.get("resume_text") and (existing_candidate.get("resume_text") != kwargs.get("resume_text")):
                logger.debug("Resume text has changed, updating resume_vector")
                resume_vector = get_embedding(kwargs.get("resume_text"))
                kwargs["resume_vector"] = resume_vector
            existing_candidate.update(kwargs)
            pk = self._update_candidate(**existing_candidate)
            if not pk:
                logger.error("Failed to update existing candidate: %s", kwargs)
            return pk

# ------------------------------------------------------------------
# Candidate record search operations
# ------------------------------------------------------------------

    def search_candidates_by_resume(self, resume_text: str, limit: Optional[int] = 1, similarity_threshold = 0.9) -> List[Dict[str, Any]]:
        """Search for similar candidates by resume text."""
        if not self.enabled or not self.collection:
            return []
        limit = limit or self.similarity_top_k
        search_params = {
            "metric_type": "IP",
            "params": {"ef": 32},
        }
        resume_vector = get_embedding(resume_text)
        results: List[SearchResult] = self.collection.search(
            data=[resume_vector],
            anns_field="resume_vector",
            limit=limit,
            param=search_params,
            output_fields=_readable_fields,
        )
        hits = [result['entity'] for result in results[0][:limit] if result.score > similarity_threshold]
        
        if hits:
            return hits[0]
        else:
            return None

    def get_candidates(
        self,
        identifiers: Optional[List[str]] = None,
        names: Optional[List[str]] = None,
        job_applied: Optional[str] = None,
        limit: Optional[int] = None,
        fields = _readable_fields
    ) -> List[Dict[str, Any]]:
        """
        Query candidates by identifiers (chat_id/candidate_id/conversation_id) or by names/job_applied.
        
        Args:
            identifiers: List of chat_id, candidate_id, or conversation_id values (mutually exclusive with names/job_applied)
            names: List of candidate names (requires job_applied)
            job_applied: Single job_applied value (required with names)
            limit: Maximum number of results to return
            fields: Fields to return
            
        Returns:
            List[Dict[str, Any]]: List of candidate records
        """
        if not self.enabled or not self.collection:
            return []
        if fields is None:
            fields = _readable_fields

        # remove None from identifiers, names, and job_applied
        if identifiers:
            identifiers = [id for id in identifiers if id] or None
        if names:
            names = [name for name in names if name] or None
        if job_applied:
            job_applied = job_applied or None
        
        # Build query expression
        if identifiers:
            # Query by identifiers: chat_id IN [...] OR candidate_id IN [...] OR conversation_id IN [...]
            identifiers = [str(id).strip() for id in identifiers if id and str(id).strip()]
            if not identifiers:
                return []
            
            quoted_ids = [f"'{id}'" for id in identifiers]
            ids_str = ', '.join(quoted_ids)
            expr_1 = f"chat_id IN [{ids_str}] OR candidate_id IN [{ids_str}] OR conversation_id IN [{ids_str}]"
            query_limit = limit or len(identifiers)
        else:
            expr_1 = None
        if names and job_applied:
            # Query by names and job_applied: name IN [...] OR job_applied == 'job'
            names = [str(n).strip() for n in names if n and str(n).strip()]
            if not names:
                return []
            
            quoted_names = [f"'{n}'" for n in names]
            names_str = ', '.join(quoted_names)
            expr_2 = f"name IN [{names_str}] AND job_applied == '{str(job_applied).strip()}'"
            query_limit = limit or len(names)
        else:
            expr_2 = None

        if expr_1 and expr_2:
            expr = f'({expr_1}) OR ({expr_2})'
        else:
            expr = expr_1 or expr_2
        
        # Execute query
        results: List[Dict[str, Any]] = self.collection.query(
            expr=expr,
            output_fields=fields,
            limit=query_limit,
        )

        # remove empty fields
        valid_results = [{k: v for k, v in result.items() if v} for result in results]
        
        return valid_results
    


# ------------------------------------------------------------------
# Candidate record persistence - Module-level convenience functions
# ------------------------------------------------------------------

# Create global instance with safe defaults
# Load configuration from environment or config file
def _create_candidate_store() -> CandidateStore:
    """Create candidate store instance with configuration."""
    from .config import settings
    
    # Use settings from config.py
    endpoint = settings.ZILLIZ_ENDPOINT
    user = settings.ZILLIZ_USER
    password = settings.ZILLIZ_PASSWORD
    collection_name = settings.ZILLIZ_COLLECTION_NAME
    embedding_dim = settings.ZILLIZ_EMBEDDING_DIM
    similarity_top_k = settings.ZILLIZ_SIMILARITY_TOP_K
    
    if not endpoint:
        logger.info("No Zilliz endpoint configured, candidate store will be disabled")
        endpoint = "http://localhost:19530"

    return CandidateStore(
        endpoint=endpoint,
        collection_name=collection_name,
        embedding_dim=embedding_dim,
        similarity_top_k=similarity_top_k,
        user=user if user else None,
        password=password if password else None,
    )


# Embeddings ----------------------------------------------------
@lru_cache(maxsize=1000)
def get_embedding(text: str) -> Optional[List[float]]:
    """Generate embedding for text."""
    if not candidate_store.enabled:
        return None
    from .assistant_actions import _openai_client
    response = _openai_client.embeddings.create(
        model=settings.ZILLIZ_EMBEDDING_MODEL, 
        input=text[:4096],
        dimensions=settings.ZILLIZ_EMBEDDING_DIM,
    )
    return response.data[0].embedding



candidate_store = _create_candidate_store()

__all__ = ["candidate_store", "CandidateStore", "upsert_candidate"]
