"""Zilliz/Milvus-backed QA and candidate interaction store integration."""
from __future__ import annotations

import json
from datetime import datetime
from typing import Any, Dict, Iterable, List, Optional

from pymilvus import (
    Collection,
    CollectionSchema,
    DataType,
    FieldSchema,
    SearchResult,
    connections,
    utility,
    entity,
)
# Note: Milvus embedding functions are not supported in current Zilliz Cloud version
# Keeping manual embedding generation for now
EMBEDDING_FUNCTION_AVAILABLE = False

from .global_logger import logger
from .config import settings

class CandidateStore:
    def __init__(
        self,
        endpoint: str,
        collection_name: str = settings.ZILLIZ_COLLECTION_NAME,
        embedding_dim: int = settings.ZILLIZ_EMBEDDING_DIM,
        similarity_top_k: int = settings.ZILLIZ_SIMILARITY_TOP_K,
        token: Optional[str] = None,
        user: Optional[str] = None,
        password: Optional[str] = None,
        secure: Optional[bool] = None,
    ) -> None:
        self.endpoint = endpoint
        self.token = token
        self.user = user
        self.password = password
        self.collection_name = collection_name
        self.embedding_dim = embedding_dim
        self.similarity_top_k = similarity_top_k
        self.secure = secure if secure is not None else endpoint.startswith("https://")
        self.collection: Optional[Collection] = None
        self.embedding_function = None
        self.enabled = self._connect_and_prepare()

    # ------------------------------------------------------------------
    # Connection helpers
    # ------------------------------------------------------------------
    def _connect_and_prepare(self) -> bool:
        try:
            logger.info("Connecting to Zilliz endpoint %s", self.endpoint)
            connect_args: Dict[str, Any] = {"alias": "default"}
            if self.token:
                connect_args.update({
                    "uri": self.endpoint,
                    "token": self.token,
                    "secure": self.secure,
                })
            else:
                connect_args.update(
                    {
                        "uri": self.endpoint,
                        "user": self.user,
                        "password": self.password,
                        "secure": self.secure,
                    }
                )
            connections.connect(**connect_args)
            
            # Note: Embedding functions not supported in current Zilliz version
            # Manual embedding generation is handled in assistant_actions.py
            
            self.collection = self._ensure_candidate_collection(self.collection_name)
            return True
        except Exception as exc:
            logger.exception("Failed to connect to Zilliz: %s", exc)
            return False


    def _ensure_candidate_collection(self, name: str) -> Collection:
        if not utility.has_collection(name):
            logger.error("Creating candidate collection %s", name)
            raise ValueError(f"Candidate collection {name} does not exist")
        else:
            dim = self.embedding_dim if self.embedding_dim else settings.ZILLIZ_EMBEDDING_DIM
            fields = [
                # Primary key - auto-generated by Milvus
                FieldSchema(name="candidate_id", dtype=DataType.VARCHAR, max_length=64, is_primary=True, auto_id=True),
                FieldSchema(name="resume_vector", dtype=DataType.FLOAT_VECTOR, dim=dim),
                
                # UI chat_id - used for UI operations
                FieldSchema(name="chat_id", dtype=DataType.VARCHAR, max_length=100, nullable=True),
                
                # Basic candidate info
                FieldSchema(name="name", dtype=DataType.VARCHAR, max_length=200, nullable=True),
                FieldSchema(name="job_applied", dtype=DataType.VARCHAR, max_length=128, nullable=True),
                FieldSchema(name="last_message", dtype=DataType.VARCHAR, max_length=2048, nullable=True),
                FieldSchema(name="resume_text", dtype=DataType.VARCHAR, max_length=25000, nullable=True),
                FieldSchema(name="metadata", dtype=DataType.JSON, nullable=True),
                FieldSchema(name="updated_at", dtype=DataType.VARCHAR, max_length=64, nullable=True),
                FieldSchema(name="analysis", dtype=DataType.JSON, nullable=True),
                
                # Additional fields
                FieldSchema(name="stage", dtype=DataType.VARCHAR, max_length=20, nullable=True),
                FieldSchema(name="full_resume", dtype=DataType.VARCHAR, max_length=10000, nullable=True),
                FieldSchema(name="thread_id", dtype=DataType.VARCHAR, max_length=100, nullable=True),
            ]
            schema = CollectionSchema(fields, description="Candidate profiles")
            collection = Collection(name=name, schema=schema)
            index_params = {
                "index_type": "AUTOINDEX",
                "metric_type": "IP",
                "params": {},
            }
            collection.create_index(field_name="resume_vector", index_params=index_params)
            collection.create_index(field_name="chat_id", index_params=index_params)
        collection = Collection(name)
        logger.info("Loading collection %s", name)
        collection.load()
        return collection


    # ------------------------------------------------------------------
    # Candidate operations
    # ------------------------------------------------------------------
    def insert_candidate(
        self,
        *,
        chat_id: str,
        name: str,
        job_applied: str,
        last_message: str,
        resume_text: str,
        resume_vector: Iterable[float],
        thread_id: str,
        analysis: Optional[Dict[str, Any]] = None,
        metadata: Optional[Dict[str, Any]] = None,
        stage: Optional[str] = None,
        full_resume: Optional[str] = None,
    ) -> bool:
        """Insert a new candidate record."""
        if not self.enabled or not self.collection:
            return False
        
        # Prepare data for insert (don't include candidate_id - auto-generated)
        data = {
            "chat_id": chat_id,
            "name": name,
            "job_applied": job_applied,
            "last_message": last_message,
            "resume_text": resume_text,
            "analysis": analysis or {},
            "metadata": metadata or {},
            "updated_at": datetime.now().isoformat(),
            "stage": stage,
            "full_resume": full_resume,
            "thread_id": thread_id,
            'resume_vector': resume_vector, 
        }
        
        # Remove None values (they'll be NULL in database)
        data = {k: v for k, v in data.items() if v}
        
        try:
            self.collection.insert([data])
            self.collection.flush()
            return True
        except Exception as exc:
            logger.exception("Failed to insert candidate %s: %s", chat_id, exc)
            return False

    def update_candidate(
        self,
        candidate_id: str,
        **kwargs,
    ) -> bool:
        """update candidate data using Milvus native upsert."""
        
        # Only include fields that are not None
        data = {k: v for k, v in kwargs.items() if v is not None}
        data['updated_at'] = datetime.now().isoformat()
        data['candidate_id'] = candidate_id
        
        try:
            # Use Milvus native upsert - it handles insert/update automatically
            self.collection.upsert([data], partial=True)
            self.collection.flush()
            return True
        except Exception as exc:
            logger.exception("Failed to update candidate %s: %s", candidate_id, exc)
            return False


    def search_candidates(self, resume_vector: List[float], top_k: Optional[int] = 1, similarity_threshold = 0.9) -> List[Dict[str, Any]]:
        """Search for similar candidates by resume vector."""
        if not self.enabled or not self.collection:
            return []
        limit = top_k or self.similarity_top_k
        search_params = {
            "metric_type": "IP",
            "params": {"ef": 32},
        }
        results: List[SearchResult] = self.collection.search(
            data=[resume_vector],
            anns_field="resume_vector",
            limit=limit,
            param=search_params,
        )
        hits: List[Dict[str, Any]] = []
        for hit in results[0][:limit]:
            score = hit.score
            if similarity_threshold is not None and score < similarity_threshold:
                continue
            hits.append(
                {
                    "score": score,
                    "entity": hit.entity,
                }
            )
        if hits:
            return hits[0]
        else:
            return None


    def get_candidate_by_chat_id(self, chat_id: str, fields: Optional[List[str]] = ["*"]) -> Optional[Dict[str, Any]]:
        """Retrieve a single candidate record by chat_id."""
        if not chat_id or not self.enabled or not self.collection:
            return None

        expr = f"chat_id == {json.dumps(chat_id)}"
        results: List[Dict[str, Any]] = self.collection.query(
            expr=expr,
            output_fields=fields,
            limit=1,
        )

        if not results:
            return None
        return results[0]

    def update_candidate_metadata(self, candidate_id: str, metadata: Dict[str, Any]) -> bool:
        """Merge metadata updates for a candidate without touching other fields."""
        if not candidate_id or not self.enabled or not self.collection:
            return False

        payload = {
            "candidate_id": candidate_id,
            "metadata": metadata or {},
            "updated_at": datetime.now().isoformat(),
        }

        try:
            self.collection.upsert([payload], partial=True)
            self.collection.flush()
        except Exception as exc:  # pragma: no cover - Milvus errors surface here
            logger.exception("Failed to update metadata for %s: %s", candidate_id, exc)
            return False
        return True

# ------------------------------------------------------------------
# Candidate record persistence
# ------------------------------------------------------------------



# Create global instance with safe defaults
# Load configuration from environment or config file
def _create_candidate_store() -> CandidateStore:
    """Create candidate store instance with configuration."""
    from .config import settings
    
    # Use settings from config.py
    endpoint = settings.ZILLIZ_ENDPOINT
    user = settings.ZILLIZ_USER
    password = settings.ZILLIZ_PASSWORD
    collection_name = settings.ZILLIZ_COLLECTION_NAME
    embedding_dim = settings.ZILLIZ_EMBEDDING_DIM
    similarity_top_k = settings.ZILLIZ_SIMILARITY_TOP_K
    
    if not endpoint:
        logger.info("No Zilliz endpoint configured, candidate store will be disabled")
        endpoint = "http://localhost:19530"

    return CandidateStore(
        endpoint=endpoint,
        collection_name=collection_name,
        embedding_dim=embedding_dim,
        similarity_top_k=similarity_top_k,
        user=user if user else None,
        password=password if password else None,
    )

default_store = _create_candidate_store()

candidate_store = default_store

__all__ = ["candidate_store", "CandidateStore"]
